{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import math\n",
    "from sklearn import preprocessing,svm\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Skin Thickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes Pedigree Index</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
       "0            6      148              72              35        0  33.6   \n",
       "1            1       85              66              29        0  26.6   \n",
       "2            8      183              64               0        0  23.3   \n",
       "3            1       89              66              23       94  28.1   \n",
       "4            0      137              40              35      168  43.1   \n",
       "\n",
       "   Diabetes Pedigree Index  Age  Outcome  \n",
       "0                    0.627   50        1  \n",
       "1                    0.351   31        0  \n",
       "2                    0.672   32        1  \n",
       "3                    0.167   21        0  \n",
       "4                    2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv', header=None)\n",
    "print(data.shape)\n",
    "data.columns = ['Pregnancies','Glucose','Blood Pressure','Skin Thickness',\n",
    "                  'Insulin', 'BMI','Diabetes Pedigree Index', 'Age', 'Outcome']\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    500\n",
      "1    268\n",
      "Name: Outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "positive_counts = data['Outcome'].value_counts()\n",
    "print(positive_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = np.array(data[['Pregnancies','Glucose','Blood Pressure','Skin Thickness',\n",
    "                  'Insulin', 'BMI','Diabetes Pedigree Index', 'Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "y = np.asarray(data['Outcome'])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(Features).transform(Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (614, 8) (614,)\n",
      "Test set: (154, 8) (154,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "#### This function implements logistic regression and can use different numerical optimizers to find parameters, including ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "Labels = y.reshape(y.shape[0],)\n",
    "Labels = np.array(Labels)\n",
    "Features = np.array(Features)\n",
    "print(Labels.shape)\n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=5, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "nr.seed(3456)\n",
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100, 1000]}\n",
    "## Define the logistic regression model\n",
    "logistic_clf =LogisticRegression() \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "lr_clf = ms.GridSearchCV(estimator = logistic_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "lr_clf.fit(Features, Labels)\n",
    "lr_c=lr_clf.best_estimator_.C\n",
    "print(lr_clf.best_estimator_.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg\n"
     ]
    }
   ],
   "source": [
    "nr.seed(3456)\n",
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga' ],\"max_iter\":[10000]}\n",
    "## Define the logistic regression model\n",
    "logistic_clf =LogisticRegression() \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "lr_clf = ms.GridSearchCV(estimator = logistic_clf, param_grid = param_grid,\n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "lr_clf.fit(Features, Labels)\n",
    "lr_solver=lr_clf.best_estimator_.solver\n",
    "print(lr_clf.best_estimator_.solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(1115)\n",
    "logistic_mod = LogisticRegression(C = lr_c,solver = lr_solver,max_iter=10000) \n",
    "logistic_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathematical function used for the transformation is known as the kernel function, and can be of different types, such as:\n",
    "\n",
    "    1.Linear\n",
    "    2.Polynomial\n",
    "    3.Radial basis function (RBF)\n",
    "    4.Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n"
     ]
    }
   ],
   "source": [
    "nr.seed(3456)\n",
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"kernel\":['linear','rbf','sigmoid']}\n",
    "## Define the SVM model\n",
    "svc_clf = svm.SVC() \n",
    "## Perform the grid search over the parameters\n",
    "clf = ms.GridSearchCV(estimator = svc_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "clf.fit(Features, Labels)\n",
    "svm_kernel=clf.best_estimator_.kernel\n",
    "print(clf.best_estimator_.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "nr.seed(3456)\n",
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"C\": [1, 10, 100, 1000], \"gamma\":[1.0/50.0, 1.0/200.0, 1.0/500.0, 1.0/1000.0]}\n",
    "## Define the SVM model\n",
    "svc_clf = svm.SVC() \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "clf = ms.GridSearchCV(estimator = svc_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "clf.fit(Features, Labels)\n",
    "svm_c=clf.best_estimator_.C\n",
    "svm_gamma=clf.best_estimator_.gamma\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(1115)\n",
    "svm_mod = svm.SVC(C = svm_c,gamma = svm_gamma,\n",
    "                  kernel = svm_kernel,\n",
    "                  probability=True) \n",
    "svm_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\":[1,10,100,500,1000]}\n",
    "## Define the random forest model\n",
    "nr.seed(3456)\n",
    "rf_clf = RandomForestClassifier(class_weight = \"balanced\") # class_weight = {0:0.33, 1:0.67}) \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(4455)\n",
    "rf_clf = ms.GridSearchCV(estimator = rf_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "rf_clf.fit(Features, Labels)\n",
    "rf_n=rf_clf.best_estimator_.n_estimators\n",
    "print(rf_clf.best_estimator_.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"min_samples_leaf\":[3, 5, 10, 20], \"criterion\":['gini','entropy']}\n",
    "## Define the random forest model\n",
    "nr.seed(3456)\n",
    "rf_clf = RandomForestClassifier() # class_weight = {0:0.33, 1:0.67}) \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(4455)\n",
    "rf_clf = ms.GridSearchCV(estimator = rf_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "rf_clf.fit(Features, Labels)\n",
    "rf_criterion=rf_clf.best_estimator_.criterion\n",
    "rf_leaf=rf_clf.best_estimator_.min_samples_leaf\n",
    "print(rf_clf.best_estimator_.criterion)\n",
    "print(rf_clf.best_estimator_.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=20, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=rf_n,max_depth=4,criterion=rf_criterion,min_samples_leaf=rf_leaf)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression  0.805195\n",
      "Accuracy of SVM  0.811688\n",
      "Accuracy of Random Forest  0.779221\n"
     ]
    }
   ],
   "source": [
    "probabilities =logistic_mod.predict_proba(X_test)\n",
    "scores = score_model(probabilities, 0.5)\n",
    "print('Accuracy of logistic regression  %f' % sklm.accuracy_score(y_test, scores))\n",
    "a=sklm.accuracy_score(y_test, scores)\n",
    "probabilities1 = svm_mod.predict_proba(X_test)\n",
    "scores1 = score_model(probabilities1, 0.5)\n",
    "print('Accuracy of SVM  %f' % sklm.accuracy_score(y_test, scores1))\n",
    "b=sklm.accuracy_score(y_test, scores1)\n",
    "probabilities2 = rf_clf.predict_proba(X_test)\n",
    "scores2 = score_model(probabilities2, 0.5)\n",
    "print('Accuracy of Random Forest  %f' % sklm.accuracy_score(y_test, scores2))\n",
    "c=sklm.accuracy_score(y_test, scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive        89                13\n",
      "Actual negative        17                35\n",
      "\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      102            52\n",
      "Precision    0.84          0.73\n",
      "Recall       0.87          0.67\n",
      "F1           0.86          0.70\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "\n",
    "    \n",
    "print_metrics(y_test, scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive        91                11\n",
      "Actual negative        18                34\n",
      "\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      102            52\n",
      "Precision    0.83          0.76\n",
      "Recall       0.89          0.65\n",
      "F1           0.86          0.70\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "\n",
    "    \n",
    "print_metrics(y_test, scores1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive        91                11\n",
      "Actual negative        23                29\n",
      "\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      102            52\n",
      "Precision    0.80          0.72\n",
      "Recall       0.89          0.56\n",
      "F1           0.84          0.63\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "\n",
    "    \n",
    "print_metrics(y_test, scores2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Our Algorithm  0.798701\n"
     ]
    }
   ],
   "source": [
    "final=a*scores + b*scores1 + c*scores2\n",
    "finalans=final/3\n",
    "def score_model1(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:]])\n",
    "finalscores = score_model1(finalans, 0.5)\n",
    "print('Accuracy of Our Algorithm  %f' % sklm.accuracy_score(y_test, finalscores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
